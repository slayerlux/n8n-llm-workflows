version: '3.8'

services:
  n8n:
    image: n8nio/n8n:1.117.0
    container_name: n8n
    restart: unless-stopped
    ports:
      - '5678:5678'
    environment:
      - N8N_HOST=localhost
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - WEBHOOK_URL=http://localhost:5678/
      # Local development: forward your LM Studio env into expressions
      - OPENAI_API_BASE=http://host.docker.internal:1234/v1
      - OPENAI_API_KEY=lm-studio
      - OPENAI_MODEL=openai/gpt-oss-20b
    volumes:
      - ./n8n_data:/home/node/.n8n
    # Local-only: allow container to reach host services like LM Studio on macOS/Windows
    extra_hosts:
      - 'host.docker.internal:host-gateway'
